{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dok.txt') as f:\n",
    "    data = [line for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \" \".join(word for word in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Diabetes adalah penyakit dimana kadar gula ditemukan berlebihan di dalam darah sehingga sering muncul keluhan mudah lapar, mudah haus, gatal-gatal, sering kencing, atau penurunan berat badan.\\n Untuk mengukur kadar gula darah bisa dilakukan pemeriksaan:\\n Gula darah sewaktu. Pemeriksaan gula acak yang bisa dilakukan sewaktu-waktu tanpa perlu puasa.\\n Gula darah puasa. Pemeriksaan yang dilakukan setelah Anda puasa selama 8 jam.\\n Gula darah 2 jam setelah makan.\\n HbA1C. Kadar gula yang ada di dalam sel darah merah, sehingga dapat mengetahui rata-rata kadar gula darah dalam 3 bulan terakhir sebelum pemeriksaan.\\n Jadi tidak ada istilah diabetes sewaktu. Mungkin yang Anda maksud adalah kadar gula darah Anda tinggi pada pemeriksaan gula darah sewaktu.\\n Perihal keluhan kepala kliyengan atau terasa ringan dan mau jatuh bisa saja menandakan kadar gula Anda terlalu rendah, karena pembatasan makanan yang sangat ketat.\\n Untuk mengontrol kadar gula Anda, Anda perlu makan dan minum obat secara teratur. Yang saat ini perlu Anda lakukan adalah cek kadar gula darah ulang terlebih bila Anda sedang menjalankan ibadah puasa dan tunjukkan hasilnya ke dokter sehingga bisa diberikan obat diabetes dengan dosis yang tepat atau cukup dengan mengatur pola makan saja.\\n \"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframess = pd.DataFrame({\"Document\":[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_obj = StopWordRemoverFactory()\n",
    "stopwords_sastrawi_ind = stopwords_obj.get_stop_words()\n",
    "stopwords_nltk = stopwords.words('indonesian')\n",
    "stopwords_sastrawi_ind_plus = stopwords_sastrawi_ind + [\"sebab\",\"salah\",\"satu\",'rata', 'tahun', 'tengah', 'tinggi', 'umum', 'waktu']\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "data_copy = data\n",
    "cleanwords = []\n",
    "for t in word_tokenize(data_copy.lower()):\n",
    "    if t not in stopwords_sastrawi_ind_plus:\n",
    "        cleanwords.append(t)\n",
    "#         print(t)\n",
    "    \n",
    "stc = \"\"\n",
    "for word in cleanwords:\n",
    "    stc += word + \" \"\n",
    "data_copy = stc\n",
    "data_copy = stemmer.stem(data_copy)\n",
    "\n",
    "stc = re.sub(r\"\\d+\", \"\", data_copy) #menghapus angka\n",
    "stc = stc.translate(str.maketrans('','',string.punctuation)).lower() #menghapus tanda baca\n",
    "tokens = word_tokenize(stc)\n",
    "\n",
    "kemunculan = FreqDist(tokens)\n",
    "data_final = pd.DataFrame(kemunculan.most_common())\n",
    "data_final_new = data_final.assign(Document = f'Document 1')\n",
    "\n",
    "dataframess = pd.concat([dataframess,data_final_new])\n",
    "\n",
    "dataframess.columns = ['Document', 'Word', 'Count']\n",
    "data_final_summary = pd.pivot_table(dataframess, values='Count', index=['Document'],\n",
    "                    columns=['Word'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframess = pd.DataFrame({\"Document\":[],\n",
    "#                            \"Word\":[],\n",
    "#                            \"Count\":[]})\n",
    "# # dataframess.columns = ['Document', 'Word', 'Count']\n",
    "# idx = 1\n",
    "# def create_data(nama_file):\n",
    "#     global dataframess\n",
    "#     global idx\n",
    "#     with open(nama_file) as f:\n",
    "#         data = [line for line in f.readlines()]\n",
    "\n",
    "#         data = \" \".join(word for word in data)\n",
    "\n",
    "#         stopwords_obj = StopWordRemoverFactory()\n",
    "#         stopwords_sastrawi_ind = stopwords_obj.get_stop_words()\n",
    "#         stopwords_nltk = stopwords.words('indonesian')\n",
    "#         stopwords_sastrawi_ind_plus = stopwords_sastrawi_ind + [\"sebab\",\"salah\",\"satu\",'rata', 'tahun', 'tengah', 'tinggi', 'umum', 'waktu']\n",
    "\n",
    "#         factory = StemmerFactory()\n",
    "#         stemmer = factory.create_stemmer()\n",
    "\n",
    "#         data_copy = data\n",
    "#         cleanwords = []\n",
    "#         for t in word_tokenize(data_copy.lower()):\n",
    "#             if t not in stopwords_sastrawi_ind_plus:\n",
    "#                 cleanwords.append(t)\n",
    "#         #         print(t)\n",
    "\n",
    "#         stc = \"\"\n",
    "#         for word in cleanwords:\n",
    "#             stc += word + \" \"\n",
    "#         data_copy = stc\n",
    "#         data_copy = stemmer.stem(data_copy)\n",
    "\n",
    "#         stc = re.sub(r\"\\d+\", \"\", data_copy) #menghapus angka\n",
    "#         stc = stc.translate(str.maketrans('','',string.punctuation)).lower() #menghapus tanda baca\n",
    "#         tokens = word_tokenize(stc)\n",
    "\n",
    "#         kemunculan = FreqDist(tokens)\n",
    "#         data_final = pd.DataFrame(kemunculan.most_common())\n",
    "#         data_final_new = data_final.assign(Document = f'Document {idx}')\n",
    "\n",
    "#         dataframess = pd.concat([dataframess,data_final_new],ignore_index=True)\n",
    "\n",
    "# #         dataframess.columns = ['Document', 'Word', 'Count']\n",
    "#         data_final_summary = pd.pivot_table(dataframess, values='Count', index=['Document'],\n",
    "#                             columns=['Word'])\n",
    "#         idx +=1\n",
    "        \n",
    "#         return data_final_summary\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataframess.columns = ['Document', 'Word', 'Count']\n",
    "idx = 1\n",
    "def create_data(nama_file):\n",
    "    dataframess = pd.DataFrame({\"Document\":[]})\n",
    "    with open(nama_file) as f:\n",
    "        data = [line for line in f.readlines()]\n",
    "\n",
    "        data = \" \".join(word for word in data)\n",
    "\n",
    "        stopwords_obj = StopWordRemoverFactory()\n",
    "        stopwords_sastrawi_ind = stopwords_obj.get_stop_words()\n",
    "        stopwords_nltk = stopwords.words('indonesian')\n",
    "        stopwords_sastrawi_ind_plus = stopwords_sastrawi_ind + [\"sebab\",\"salah\",\"satu\",'rata', 'tahun', 'tengah', 'tinggi', 'umum', 'waktu']\n",
    "\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "\n",
    "        data_copy = data\n",
    "        cleanwords = []\n",
    "        for t in word_tokenize(data_copy.lower()):\n",
    "            if t not in stopwords_sastrawi_ind_plus:\n",
    "                cleanwords.append(t)\n",
    "        #         print(t)\n",
    "\n",
    "        stc = \"\"\n",
    "        for word in cleanwords:\n",
    "            stc += word + \" \"\n",
    "        data_copy = stc\n",
    "        data_copy = stemmer.stem(data_copy)\n",
    "\n",
    "        stc = re.sub(r\"\\d+\", \"\", data_copy) #menghapus angka\n",
    "        stc = stc.translate(str.maketrans('','',string.punctuation)).lower() #menghapus tanda baca\n",
    "        tokens = word_tokenize(stc)\n",
    "\n",
    "        kemunculan = FreqDist(tokens)\n",
    "        data_final = pd.DataFrame(kemunculan.most_common())\n",
    "        data_final_new = data_final.assign(Document = f'Document 1')\n",
    "\n",
    "        dataframess = pd.concat([dataframess,data_final_new])\n",
    "\n",
    "        dataframess.columns = ['Document', 'Word', 'Count']\n",
    "        data_final_summary = pd.pivot_table(dataframess, values='Count', index=['Document'],\n",
    "                            columns=['Word'])\n",
    "        \n",
    "        return data_final_summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Word</th>\n",
       "      <th>acak</th>\n",
       "      <th>atur</th>\n",
       "      <th>badan</th>\n",
       "      <th>batas</th>\n",
       "      <th>berat</th>\n",
       "      <th>cek</th>\n",
       "      <th>darah</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>dokter</th>\n",
       "      <th>dosis</th>\n",
       "      <th>...</th>\n",
       "      <th>suami</th>\n",
       "      <th>sunti</th>\n",
       "      <th>tani</th>\n",
       "      <th>tes</th>\n",
       "      <th>timbul</th>\n",
       "      <th>tingkat</th>\n",
       "      <th>tipe</th>\n",
       "      <th>toleransi</th>\n",
       "      <th>tubuh</th>\n",
       "      <th>tuju</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Word  acak  atur  badan  batas  berat  cek  darah  diabetes  dokter  dosis  \\\n",
       "0      1.0   2.0    1.0    1.0    1.0  1.0   10.0       3.0     1.0    1.0   \n",
       "1      NaN   NaN    2.0    NaN    1.0  NaN    4.0       7.0     2.0    NaN   \n",
       "\n",
       "Word  ...  suami  sunti  tani  tes  timbul  tingkat  tipe  toleransi  tubuh  \\\n",
       "0     ...    NaN    NaN   NaN  NaN     NaN      NaN   NaN        NaN    NaN   \n",
       "1     ...    3.0    1.0   1.0  1.0     1.0      1.0   3.0        1.0    2.0   \n",
       "\n",
       "Word  tuju  \n",
       "0      NaN  \n",
       "1      1.0  \n",
       "\n",
       "[2 rows x 115 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dokumen_1 = create_data('data_dok.txt')\n",
    "dokumen_2 = create_data('data_dok1.txt')\n",
    "data_gabung = pd.concat([dokumen_1,dokumen_2],ignore_index=True)\n",
    "data_gabung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Word</th>\n",
       "      <th>acak</th>\n",
       "      <th>atur</th>\n",
       "      <th>badan</th>\n",
       "      <th>batas</th>\n",
       "      <th>berat</th>\n",
       "      <th>cek</th>\n",
       "      <th>darah</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>dokter</th>\n",
       "      <th>dosis</th>\n",
       "      <th>...</th>\n",
       "      <th>suami</th>\n",
       "      <th>sunti</th>\n",
       "      <th>tani</th>\n",
       "      <th>tes</th>\n",
       "      <th>timbul</th>\n",
       "      <th>tingkat</th>\n",
       "      <th>tipe</th>\n",
       "      <th>toleransi</th>\n",
       "      <th>tubuh</th>\n",
       "      <th>tuju</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Word  acak  atur  badan  batas  berat  cek  darah  diabetes  dokter  dosis  \\\n",
       "0      1.0   2.0    1.0    1.0    1.0  1.0   10.0       3.0     1.0    1.0   \n",
       "1      0.0   0.0    2.0    0.0    1.0  0.0    4.0       7.0     2.0    0.0   \n",
       "\n",
       "Word  ...  suami  sunti  tani  tes  timbul  tingkat  tipe  toleransi  tubuh  \\\n",
       "0     ...    0.0    0.0   0.0  0.0     0.0      0.0   0.0        0.0    0.0   \n",
       "1     ...    3.0    1.0   1.0  1.0     1.0      1.0   3.0        1.0    2.0   \n",
       "\n",
       "Word  tuju  \n",
       "0      0.0  \n",
       "1      1.0  \n",
       "\n",
       "[2 rows x 115 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gabung.fillna(0,inplace=True)\n",
    "data_gabung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Word</th>\n",
       "      <th>acak</th>\n",
       "      <th>atur</th>\n",
       "      <th>badan</th>\n",
       "      <th>batas</th>\n",
       "      <th>berat</th>\n",
       "      <th>cek</th>\n",
       "      <th>darah</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>dokter</th>\n",
       "      <th>dosis</th>\n",
       "      <th>...</th>\n",
       "      <th>saja</th>\n",
       "      <th>sakit</th>\n",
       "      <th>sel</th>\n",
       "      <th>tanda</th>\n",
       "      <th>temu</th>\n",
       "      <th>tunjuk</th>\n",
       "      <th>turun</th>\n",
       "      <th>ukur</th>\n",
       "      <th>ulang</th>\n",
       "      <th>waktu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Word        acak  atur  badan  batas  berat  cek  darah  diabetes  dokter  \\\n",
       "Document                                                                    \n",
       "Document 1   1.0   2.0    1.0    1.0    1.0  1.0   10.0       3.0     1.0   \n",
       "\n",
       "Word        dosis  ...  saja  sakit  sel  tanda  temu  tunjuk  turun  ukur  \\\n",
       "Document           ...                                                       \n",
       "Document 1    1.0  ...   1.0    1.0  1.0    1.0   1.0     1.0    1.0   1.0   \n",
       "\n",
       "Word        ulang  waktu  \n",
       "Document                  \n",
       "Document 1    1.0    1.0  \n",
       "\n",
       "[1 rows x 52 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dokumen_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "idx = 0 \n",
    "for i in data_copy:\n",
    "#     data_copy[\"TULISAN\"] = stemmer.stem(data_copy[\"TULISAN\"])\n",
    "    data_copy_2.iloc[idx,2] = stemmer.stem(str(i))\n",
    "    \n",
    "    print(data_copy_2.iloc[idx,2])\n",
    "    idx = idx + 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
